{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n292ClPmVaM"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptObbWmWmVaM"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "OtTVsDYet4SK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Classes"
      ],
      "metadata": {
        "id": "ntWeqyzGCQRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogicalReasoningModel(nn.Module):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(LogicalReasoningModel, self).__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.model.config.hidden_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, context, question, options):\n",
        "        # input for the transformer model\n",
        "        inputs = [\n",
        "            self.tokenizer(\n",
        "                f\"{context} [SEP] {question} [SEP] {option}\",\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                max_length=512,\n",
        "                return_tensors=\"pt\"\n",
        "            ) for option in options\n",
        "        ]\n",
        "\n",
        "        # Process each option and aggregate\n",
        "        outputs = []\n",
        "        for input_data in inputs:\n",
        "            input_data = {k: v.to(self.model.device) for k, v in input_data.items()}\n",
        "            output = self.model(**input_data).last_hidden_state[:, 0, :]  # CLS token output\n",
        "            outputs.append(output)\n",
        "\n",
        "        # Stack outputs and classify\n",
        "        logits = torch.stack([self.classifier(output) for output in outputs], dim=1)\n",
        "        return logits\n",
        "\n",
        "class LogicalReasoningDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length, is_train=True):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "        context = row['context']\n",
        "        question = row['question']\n",
        "        options = eval(row['answers'])\n",
        "        label = row['label'] if self.is_train else -1\n",
        "\n",
        "        return context, question, options, label\n"
      ],
      "metadata": {
        "id": "9UPFmYXh2c2w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration"
      ],
      "metadata": {
        "id": "0V2_MS4V2oFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "NUM_LABELS = 4\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 11\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "def load_data(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "train_file_path = \"train.csv\"\n",
        "test_file_path = \"test.csv\"\n",
        "submission_file_path = \"sample_submission.csv\"\n",
        "\n",
        "train_data = load_data(train_file_path)\n",
        "test_data = load_data(test_file_path)\n",
        "submission_template = load_data(submission_file_path)\n",
        "\n",
        "train_dataset = LogicalReasoningDataset(train_data, AutoTokenizer.from_pretrained(MODEL_NAME), max_length=512, is_train=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Initialise\n",
        "model = LogicalReasoningModel(model_name=MODEL_NAME, num_labels=NUM_LABELS)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Optimiser and loss\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "g-7OAhVM26_t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "cDK6mjtC3CbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        context, question, options, labels = batch\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(context[0], question[0], options[0])  # Process first example in batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(logits.view(-1, NUM_LABELS), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), \"logical_reasoning_model.pth\")\n"
      ],
      "metadata": {
        "id": "4z2OhF24t4jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "jvGdIoa23HSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prediction on test set\n",
        "def predict_test_data(model, test_data, tokenizer, device):\n",
        "    model.eval()\n",
        "    test_dataset = LogicalReasoningDataset(test_data, tokenizer, max_length=512, is_train=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for context, question, options, _ in test_loader:\n",
        "            logits = model(context[0], question[0], options[0])\n",
        "            probabilities = torch.softmax(logits, dim=-1)\n",
        "            best_option = torch.argmax(probabilities, dim=-1).item()\n",
        "            predictions.append(best_option)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Generate predictions\n",
        "predictions = predict_test_data(model, test_data, AutoTokenizer.from_pretrained(MODEL_NAME), device)\n",
        "\n",
        "# Create submission file\n",
        "submission_template['label'] = predictions\n",
        "submission_template.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "kMCa5nW22iV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}